{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LayoutLMv3 Experiment\n",
        "Evaluating LayoutLMv3 for extracting key data fields from invoices.\n",
        "\n"
      ],
      "metadata": {
        "id": "jdjTpPeWbR0I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b18a5b78"
      },
      "source": [
        "# config\n",
        "\n",
        "note: pytesseract is necesseriy for running the LayoutLMv3 Processer!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9e287d98",
        "outputId": "7c4962a2-c3e2-4de4-9e45-cdb74b2315a0"
      },
      "source": [
        "import os\n",
        "from transformers import LayoutLMv3ForQuestionAnswering, AutoTokenizer, LayoutLMv3Processor, LayoutLMv3FeatureExtractor\n",
        "from PIL import Image\n",
        "\n",
        "invoice_file = [\"/content/BRE-03_page1.png\"] # add your png file path here\n",
        "\n",
        "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
        "model = LayoutLMv3ForQuestionAnswering.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/layoutlmv3-base\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LayoutLMv3ForQuestionAnswering were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['qa_outputs.dense.bias', 'qa_outputs.dense.weight', 'qa_outputs.out_proj.bias', 'qa_outputs.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "LnRb58PlaY7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bac0b5d"
      },
      "source": [
        "# Picture pre processing and OCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "34648bfe",
        "outputId": "5b8bed7a-8050-4ef2-dff7-b54ceb43d6d8"
      },
      "source": [
        "image_path = invoice_file[0]\n",
        "\n",
        "try:\n",
        "    # Open and convert the image to RGB\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Process the image using the loaded processor\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    # Use the loaded model to get outputs\n",
        "    outputs = model(**inputs)\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "\n",
        "    # Determine the start and end indices\n",
        "    start_index = start_logits.argmax()\n",
        "    end_index = end_logits.argmax()\n",
        "\n",
        "    # Get input_ids from processed inputs\n",
        "    input_ids = inputs[\"input_ids\"][0]\n",
        "\n",
        "    # Decode the tokens\n",
        "    extracted_text = tokenizer.decode(input_ids[start_index:end_index+1])\n",
        "\n",
        "    # Print the extracted text\n",
        "    print(\"Extracted Text from Image:\")\n",
        "    print(extracted_text)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {image_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1731: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text from Image:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab1d74f1"
      },
      "source": [
        "# End-to-End Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ee04bbbd",
        "outputId": "2eaceb6b-8778-40b4-919d-5d6bd70dab48"
      },
      "source": [
        "# Define the questions\n",
        "questions = [\n",
        "    \"What is the total amount?\",\n",
        "    \"Who is the recipient?\"\n",
        "]\n",
        "\n",
        "extracted_answers = {}\n",
        "image_path = invoice_file[0]\n",
        "\n",
        "try:\n",
        "    # Open and convert the image to RGB\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    for question in questions:\n",
        "        # Prepare inputs for the model\n",
        "        inputs = processor(images=image, text=question, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
        "\n",
        "        # Get model outputs\n",
        "        outputs = model(**inputs)\n",
        "        start_logits = outputs.start_logits\n",
        "        end_logits = outputs.end_logits\n",
        "\n",
        "        # Find the answer span\n",
        "        start_index = start_logits.argmax()\n",
        "        end_index = end_logits.argmax()\n",
        "\n",
        "        # Decode the answer\n",
        "        answer_tokens = inputs[\"input_ids\"][0, start_index : end_index + 1]\n",
        "        answer = tokenizer.decode(answer_tokens)\n",
        "\n",
        "        # Store answers associated with the image path and question\n",
        "        if image_path not in extracted_answers:\n",
        "            extracted_answers[image_path] = {}\n",
        "        extracted_answers[image_path][question] = answer\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {image_path} was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred with file {image_path}: {e}\")\n",
        "\n",
        "# Print the extracted answers\n",
        "print(\"\\nExtracted Answers:\")\n",
        "if extracted_answers:\n",
        "    for image_path, answers in extracted_answers.items():\n",
        "        print(f\"Answers for {image_path}:\")\n",
        "        for question, answer in answers.items():\n",
        "            print(f\"  Question: {question}\")\n",
        "            print(f\"  Answer: {answer}\")\n",
        "else:\n",
        "    print(\"No answers were extracted.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1731: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1731: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracted Answers:\n",
            "Answers for /content/BRE-03_page1.png:\n",
            "  Question: What is the total amount?\n",
            "  Answer: \n",
            "  Question: Who is the recipient?\n",
            "  Answer: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0b96a4d"
      },
      "source": [
        "# Turn Text into Lines with Postions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "840ee4cc",
        "outputId": "76a3ff58-23be-4a58-9242-0369dfa3a2e5"
      },
      "source": [
        "# Third Main Section: Text Chunking and Bounding Boxes\n",
        "\n",
        "image_path = invoice_file[0] # Define the image path\n",
        "\n",
        "try:\n",
        "    # Open and convert the image to RGB\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Using the processor to get encoding which includes bbox and text\n",
        "    encoding = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    # Extract tokens, bounding boxes, and text\n",
        "    tokens = encoding.input_ids[0]\n",
        "    bboxes = encoding.bbox[0]\n",
        "    words = processor.tokenizer.batch_decode(tokens, skip_special_tokens=True)\n",
        "\n",
        "    # Create a list of dictionaries for each token\n",
        "    token_info = []\n",
        "    for token, bbox, word in zip(tokens, bboxes, words):\n",
        "        # Filter out empty words or special tokens if necessary\n",
        "        if word.strip() and token not in processor.tokenizer.all_special_ids:\n",
        "             token_info.append({\"text\": word, \"bbox\": bbox.tolist(), \"token_id\": token.item()})\n",
        "\n",
        "    # Sort tokens primarily by y-coordinate to group by line\n",
        "    token_info_sorted_y = sorted(token_info, key=lambda x: x[\"bbox\"][1])\n",
        "\n",
        "    # Group tokens into lines based on vertical proximity\n",
        "    line_tolerance = 10 # Pixels; adjust as needed\n",
        "\n",
        "    sorted_lines = [] # List of tuples (y_coordinate, list_of_tokens_in_line)\n",
        "    current_line = []\n",
        "    current_y = -1\n",
        "\n",
        "    for token in token_info_sorted_y:\n",
        "        # Use the y-coordinate of the top-left corner for grouping\n",
        "        token_y = token[\"bbox\"][1]\n",
        "\n",
        "        if not current_line:\n",
        "            current_line.append(token)\n",
        "            current_y = token_y\n",
        "        elif abs(token_y - current_y) < line_tolerance:\n",
        "            current_line.append(token)\n",
        "            # Update current_y to the average y of the line for better grouping\n",
        "            current_y = sum(t[\"bbox\"][1] for t in current_line) / len(current_line)\n",
        "        else:\n",
        "            # Sort tokens within the line by x-coordinate\n",
        "            current_line_sorted_x = sorted(current_line, key=lambda x: x[\"bbox\"][0])\n",
        "            sorted_lines.append((current_y, current_line_sorted_x))\n",
        "            current_line = [token]\n",
        "            current_y = token_y\n",
        "\n",
        "    # Add the last line\n",
        "    if current_line:\n",
        "         current_line_sorted_x = sorted(current_line, key=lambda x: x[\"bbox\"][0])\n",
        "         sorted_lines.append((current_y, current_line_sorted_x))\n",
        "\n",
        "    print(f\"Processed image and grouped tokens into {len(sorted_lines)} lines.\")\n",
        "\n",
        "    # Split lines into Chunks\n",
        "    chunk_gap_threshold = 40   # Pixel; adjust as needed or calculate dynamically\n",
        "\n",
        "    chunks = []  # List of lists; each inner list contains the tokens of a chunk\n",
        "\n",
        "    for y, line_tokens in sorted_lines:\n",
        "        # Sort tokens in the line left->right\n",
        "        line_tokens_sorted = sorted(line_tokens, key=lambda x: x[\"bbox\"][0])\n",
        "        if not line_tokens_sorted:\n",
        "            continue\n",
        "\n",
        "        current_chunk = [line_tokens_sorted[0]]\n",
        "\n",
        "        for tok in line_tokens_sorted[1:]:\n",
        "            prev_right = current_chunk[-1][\"bbox\"][2]   # right edge of the last token\n",
        "            gap       = tok[\"bbox\"][0] - prev_right     # distance to the next token's start\n",
        "\n",
        "            # If gap is too large, start a new chunk\n",
        "            if gap > chunk_gap_threshold:\n",
        "                chunks.append(current_chunk)\n",
        "                current_chunk = [tok]\n",
        "            else:\n",
        "                current_chunk.append(tok)\n",
        "\n",
        "        # Append the last chunk of the line\n",
        "        chunks.append(current_chunk)\n",
        "\n",
        "    # Convert tokens to Text + Collective BBox per Chunk\n",
        "    chunk_objects = []\n",
        "    for chunk in chunks:\n",
        "        # Assemble raw text; .strip() removes leading/trailing whitespace\n",
        "        chunk_text = \"\".join(t[\"text\"] for t in chunk).strip()\n",
        "        if not chunk_text:          # skip empty chunks\n",
        "            continue\n",
        "\n",
        "        # Collective BBox of the chunk\n",
        "        min_x = min(t[\"bbox\"][0] for t in chunk)\n",
        "        min_y = min(t[\"bbox\"][1] for t in chunk)\n",
        "        max_x = max(t[\"bbox\"][2] for t in chunk)\n",
        "        max_y = max(t[\"bbox\"][3] for t in chunk)\n",
        "\n",
        "        chunk_objects.append(\n",
        "            {\"text\": chunk_text,\n",
        "             \"bbox\": [min_x, min_y, max_x, max_y]}\n",
        "        )\n",
        "\n",
        "    # Print the identified chunks\n",
        "    print(\"\\nGefundene Chunks:\")\n",
        "    for obj in chunk_objects:\n",
        "        print(obj)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {image_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error processing file {image_path}: {e}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed image and grouped tokens into 33 lines.\n",
            "\n",
            "Gefundene Chunks:\n",
            "{'text': 'USTERMANA', 'bbox': [239, 78, 333, 86]}\n",
            "{'text': 'Mustermann GmbH.', 'bbox': [635, 113, 782, 123]}\n",
            "{'text': 'Test 123', 'bbox': [633, 130, 694, 139]}\n",
            "{'text': 'Abs.: Mustermann GmbH. | HauptstraBe 123 | 5020 Salzburg', 'bbox': [106, 143, 458, 153]}\n",
            "{'text': '5020 Salzburg Osterreich', 'bbox': [634, 144, 821, 157]}\n",
            "{'text': 'Tel.:+43 1234 123456', 'bbox': [633, 161, 790, 170]}\n",
            "{'text': 'Herr Dr. Hubert Brinkmann', 'bbox': [122, 184, 318, 193]}\n",
            "{'text': 'office@mustermann.com', 'bbox': [627, 176, 815, 195]}\n",
            "{'text': 'Hauptstrasse 125/7/3', 'bbox': [122, 202, 278, 213]}\n",
            "{'text': '83395 BERLIN', 'bbox': [121, 219, 222, 228]}\n",
            "{'text': 'DEUTSCHLAND', 'bbox': [122, 237, 234, 245]}\n",
            "{'text': 'Rechnung: Re-2/2015', 'bbox': [740, 270, 898, 281]}\n",
            "{'text': 'Datum: 12.03.2015', 'bbox': [762, 288, 898, 296]}\n",
            "{'text': 'Kundennummer: 11', 'bbox': [753, 305, 894, 314]}\n",
            "{'text': 'Rechnung', 'bbox': [443, 326, 566, 345]}\n",
            "{'text': 'Rechnung Re-2/2015', 'bbox': [107, 351, 271, 362]}\n",
            "{'text': 'Sehr geehrter Herr Dr. Brinkmann,', 'bbox': [106, 376, 356, 387]}\n",
            "{'text': 'vielen Dank fiir Ihr Vertrauen in unsere Produkte. Wir hoffen, Sie sind zufrieden und wurden uns freuen,', 'bbox': [109, 398, 868, 408]}\n",
            "{'text': 'wieder von Ihnen zu horen.', 'bbox': [109, 414, 308, 423]}\n",
            "{'text': '(Dies ist ein Beispiel der Rechnungsvorlage Standard).', 'bbox': [110, 445, 511, 457]}\n",
            "{'text': 'Pos. Bezeichnung', 'bbox': [108, 493, 267, 505]}\n",
            "{'text': 'Menge Einzelpreis', 'bbox': [509, 493, 656, 505]}\n",
            "{'text': 'Gesamtpreis', 'bbox': [804, 493, 901, 505]}\n",
            "{'text': '1.1', 'bbox': [110, 510, 126, 523]}\n",
            "{'text': 'Farbe schwarz', 'bbox': [169, 511, 271, 520]}\n",
            "{'text': '5,00 Liter', 'bbox': [496, 511, 562, 521]}\n",
            "{'text': '35,00', 'bbox': [617, 511, 656, 521]}\n",
            "{'text': '175,00 €', 'bbox': [841, 511, 901, 521]}\n",
            "{'text': 'Dunkel wie die Nacht.', 'bbox': [168, 528, 312, 536]}\n",
            "{'text': '1.2', 'bbox': [110, 545, 127, 554]}\n",
            "{'text': 'Farbe blau', 'bbox': [169, 545, 243, 554]}\n",
            "{'text': '5,00 Liter', 'bbox': [496, 545, 562, 555]}\n",
            "{'text': '38,50', 'bbox': [617, 545, 656, 555]}\n",
            "{'text': '192,50 €', 'bbox': [841, 545, 901, 555]}\n",
            "{'text': 'Blau wie der Himmel.', 'bbox': [168, 562, 307, 570]}\n",
            "{'text': 'Netto:', 'bbox': [678, 588, 733, 601]}\n",
            "{'text': '308,82 €', 'bbox': [835, 589, 900, 599]}\n",
            "{'text': '19% USt.:', 'bbox': [657, 607, 733, 616]}\n",
            "{'text': '58,68 €', 'bbox': [845, 607, 900, 617]}\n",
            "{'text': 'Leistungsdatum = Datum des Dokuments', 'bbox': [108, 620, 384, 631]}\n",
            "{'text': 'Brutto:', 'bbox': [679, 619, 732, 634]}\n",
            "{'text': '367,50 €', 'bbox': [835, 624, 900, 634]}\n",
            "{'text': 'Zahlungsziel: 14 Tage.', 'bbox': [105, 688, 266, 699]}\n",
            "{'text': 'Mit freundlichen GriiBen,', 'bbox': [106, 720, 287, 730]}\n",
            "{'text': 'Max Mustermann', 'bbox': [106, 752, 233, 761]}\n",
            "{'text': 'Mustermann GmbH.', 'bbox': [444, 922, 560, 929]}\n",
            "{'text': 'HauptstraBe 123 5020 Salzburg Osterreich', 'bbox': [379, 933, 625, 944]}\n",
            "{'text': 'Tel.:+43 1234 123456 office@mustermann.com', 'bbox': [364, 947, 640, 955]}\n",
            "{'text': 'St.-Nr.: 23/123/456/789UID: ATU12345678 IBAN: AT491700000122001632', 'bbox': [286, 960, 718, 968]}\n"
          ]
        }
      ]
    }
  ]
}